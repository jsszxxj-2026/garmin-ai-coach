"""
GarminCoach - FastAPI Application
æä¾› RESTful API æ¥å£ï¼Œæ•´åˆ Garmin æ•°æ®å’Œ AI æ•™ç»ƒåˆ†æã€‚
"""
import logging
import sys
import os
import time
from datetime import date, datetime, timedelta
from typing import Any, Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# é…ç½®å…¨å±€ Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("ProjectRunner")

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from sqlalchemy.orm import Session

from backend.app.services.garmin_client import GarminClient
from backend.app.services.data_processor import DataProcessor
from backend.app.services.gemini_service import GeminiService
from backend.app.db.crud import (
    get_activities_by_date,
    get_cached_analysis,
    get_daily_summary_by_date,
    get_or_create_user,
    get_training_plans_in_range,
    save_analysis,
    upsert_activities,
    upsert_daily_summary,
    upsert_training_plans,
)
from backend.app.db.session import get_db_optional, init_db
from src.services.garmin_service import GarminService
from src.core.config import settings


# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="GarminCoach API",
    description="åŸºäº Garmin æ•°æ®å’Œ AI çš„è·‘æ­¥æ•™ç»ƒåˆ†ææœåŠ¡",
    version="1.0.0",
)


@app.on_event("startup")
def _startup() -> None:
    try:
        init_db()
    except Exception as e:
        logger.error(f"[DB] Startup init failed: {e}")

# CORS ä¸­é—´ä»¶é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒè¯·é…ç½®å…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# å“åº”æ¨¡å‹
class DailyAnalysisResponse(BaseModel):
    """æ¯æ—¥åˆ†æå“åº”æ¨¡å‹"""
    date: str
    raw_data_summary: str  # æ¸…æ´—åçš„ Markdown æ–‡æœ¬ï¼Œç”¨äºå‰ç«¯å±•ç¤ºæ•°æ®æ¦‚è§ˆ
    ai_advice: str  # Gemini çš„å»ºè®®
    charts: Optional[Dict[str, List]] = None  # å›¾è¡¨æ•°æ®ï¼ˆlabels, paces, heart_rates, cadencesï¼‰


# Mock Mode å¼€å…³ï¼ˆé€šè¿‡ .env é…ç½®ï¼‰
USE_MOCK_MODE = settings.USE_MOCK_MODE

# ä¾èµ–æ³¨å…¥ï¼šåˆå§‹åŒ–æœåŠ¡å®ä¾‹
def get_garmin_client() -> Optional[GarminClient]:
    """
    è·å– GarminClient å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰ã€‚
    
    æ³¨æ„ï¼šæ¯æ¬¡è¯·æ±‚éƒ½ä¼šåˆ›å»ºæ–°å®ä¾‹å¹¶ç™»å½•ï¼Œå¦‚æœé¢‘ç¹è°ƒç”¨å¯èƒ½è§¦å‘ Garmin é™æµã€‚
    ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨è¿æ¥æ± æˆ–ç¼“å­˜æœºåˆ¶ã€‚
    
    Mock Mode: å¦‚æœ USE_MOCK_MODE=Trueï¼Œè¿”å› Noneï¼ˆä¸éœ€è¦çœŸå®çš„å®¢æˆ·ç«¯ï¼‰ã€‚
    """
    if USE_MOCK_MODE:
        # Mock Mode: ä¸éœ€è¦çœŸå®çš„å®¢æˆ·ç«¯ï¼Œè¿”å› None
        return None
    else:
        try:
            return GarminClient()
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Garmin ç™»å½•å¤±è´¥: {str(e)}ã€‚è¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„è´¦å·å¯†ç æ˜¯å¦æ­£ç¡®ã€‚"
            )


def get_garmin_service() -> Optional[GarminService]:
    """
    è·å– GarminService å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰ã€‚
    
    ç”¨äºè·å–æ´»åŠ¨æ•°æ®ã€‚
    
    Mock Mode: å¦‚æœ USE_MOCK_MODE=Trueï¼Œè¿”å› Noneï¼ˆä¸éœ€è¦çœŸå®æœåŠ¡ï¼‰ã€‚
    """
    if USE_MOCK_MODE:
        return None
    else:
        try:
            return GarminService(settings.GARMIN_EMAIL, settings.GARMIN_PASSWORD)
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Garmin æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {str(e)}"
            )


def get_data_processor() -> DataProcessor:
    """è·å– DataProcessor å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰ã€‚"""
    return DataProcessor()


def get_gemini_service() -> GeminiService:
    """è·å– GeminiService å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰ã€‚"""
    global _gemini_singleton
    if _gemini_singleton is None:
        _gemini_singleton = GeminiService()
    return _gemini_singleton


_gemini_singleton: Optional[GeminiService] = None


def _convert_activity_for_processor(activity: Dict[str, Any]) -> Dict[str, Any]:
    """Convert the new parsed activity format into DataProcessor's expected format."""

    if not isinstance(activity, dict) or "metrics" not in activity:
        return activity

    metrics = activity.get("metrics") if isinstance(activity.get("metrics"), dict) else {}
    distance_km = metrics.get("distance_km")
    duration_s = metrics.get("duration_seconds")
    distance_m = float(distance_km) * 1000.0 if isinstance(distance_km, (int, float)) else None

    avg_speed_mps = None
    if isinstance(distance_m, (int, float)) and isinstance(duration_s, (int, float)) and float(duration_s) > 0:
        avg_speed_mps = float(distance_m) / float(duration_s)

    converted: Dict[str, Any] = {
        "type": activity.get("type"),
        "activityName": activity.get("name"),
        "distance": distance_m,
        "duration": duration_s,
        "averageHR": metrics.get("average_hr"),
        "maxHR": metrics.get("max_hr"),
        "averageSpeed": avg_speed_mps,
        "startTimeLocal": activity.get("start_time_local") or activity.get("startTimeLocal") or "",
    }

    laps = activity.get("laps") if isinstance(activity.get("laps"), list) else []
    splits: List[Dict[str, Any]] = []
    for lap in laps:
        if not isinstance(lap, dict):
            continue
        lap_distance_km = lap.get("distance_km")
        lap_duration_s = lap.get("duration_seconds")
        lap_distance_m = float(lap_distance_km) * 1000.0 if isinstance(lap_distance_km, (int, float)) else None

        lap_speed_mps = None
        if (
            isinstance(lap_distance_m, (int, float))
            and isinstance(lap_duration_s, (int, float))
            and float(lap_duration_s) > 0
        ):
            lap_speed_mps = float(lap_distance_m) / float(lap_duration_s)

        splits.append(
            {
                "lapIndex": lap.get("lap_index"),
                "distance": lap_distance_m,
                "duration": lap_duration_s,
                "averageHR": lap.get("average_hr"),
                "maxHR": lap.get("max_hr"),
                "strideLength": lap.get("stride_length_cm"),
                "groundContactTime": lap.get("ground_contact_time_ms"),
                "verticalOscillation": lap.get("vertical_oscillation_cm"),
                "verticalRatio": lap.get("vertical_ratio_percent"),
                "averageRunCadence": lap.get("cadence"),
                "averageSpeed": lap_speed_mps,
            }
        )

    converted["splits"] = splits
    return converted


def _activity_to_new_format_from_db(activity: Any) -> Dict[str, Any]:
    metrics = {
        "distance_km": activity.distance_km,
        "duration_seconds": activity.duration_seconds,
        "average_hr": activity.average_hr,
        "max_hr": activity.max_hr,
        "calories": activity.calories,
        "average_cadence": activity.average_cadence,
        "average_stride_length_cm": activity.average_stride_length_cm,
        "average_ground_contact_time_ms": activity.average_ground_contact_time_ms,
        "average_vertical_oscillation_cm": activity.average_vertical_oscillation_cm,
        "average_vertical_ratio_percent": activity.average_vertical_ratio_percent,
    }
    laps = []
    for lap in activity.laps or []:
        laps.append(
            {
                "lap_index": lap.lap_index,
                "distance_km": lap.distance_km,
                "duration_seconds": lap.duration_seconds,
                "average_hr": lap.average_hr,
                "max_hr": lap.max_hr,
                "cadence": lap.cadence,
                "stride_length_cm": lap.stride_length_cm,
                "ground_contact_time_ms": lap.ground_contact_time_ms,
                "vertical_oscillation_cm": lap.vertical_oscillation_cm,
                "vertical_ratio_percent": lap.vertical_ratio_percent,
            }
        )

    start_time_local = ""
    if activity.start_time_local is not None:
        start_time_local = activity.start_time_local.isoformat()

    return {
        "type": activity.type,
        "name": activity.name,
        "activity_id": activity.garmin_activity_id,
        "start_time_local": start_time_local,
        "metrics": metrics,
        "laps": laps,
    }


def _build_context_from_raw(
    processor: DataProcessor,
    raw_activities_new: List[Dict[str, Any]],
    raw_health: Optional[Dict[str, Any]],
    raw_plan: List[Dict[str, Any]],
) -> tuple[Optional[str], Optional[str], Optional[str], List[Dict[str, Any]]]:
    converted_activities = [_convert_activity_for_processor(a) for a in raw_activities_new]

    activity_md: Optional[str] = None
    if converted_activities:
        simplified = [processor.simplify_activity(a) for a in converted_activities]
        activity_md = processor.format_for_llm(simplified)

    health_md: Optional[str] = None
    if raw_health:
        health_md = processor.format_health_summary(raw_health)

    plan_md: Optional[str] = None
    if raw_plan:
        plan_md = processor.format_future_plan(raw_plan)

    return activity_md, health_md, plan_md, converted_activities


@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "message": "Welcome to GarminCoach API",
        "version": "1.0.0",
        "endpoints": {
            "daily_analysis": "/api/coach/daily-analysis",
            "health": "/health",
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}


@app.get("/api/coach/daily-analysis", response_model=DailyAnalysisResponse)
async def get_daily_analysis(
    target_date: Optional[str] = None,
    force_refresh: bool = False,
    db: Optional[Session] = Depends(get_db_optional),
    processor: DataProcessor = Depends(get_data_processor),
    gemini: GeminiService = Depends(get_gemini_service),
):
    """
    è·å–æ¯æ—¥è®­ç»ƒåˆ†æå’Œ AI æ•™ç»ƒå»ºè®®ã€‚
    
    æµç¨‹ï¼š
    1. è·å–æ•°æ®ï¼šä»Šæ—¥è·‘æ­¥æ´»åŠ¨ã€æ˜¨æ™šç¡çœ ã€ä»Šæ—¥èº«ä½“ç”µé‡/HRVã€æœªæ¥3å¤©è®­ç»ƒè®¡åˆ’
    2. æ¸…æ´—æ•°æ®ï¼šä½¿ç”¨ DataProcessor å°†åŸå§‹æ•°æ®è½¬åŒ–ä¸º Markdown æ ¼å¼
    3. AI åˆ†æï¼šå°†æ¸…æ´—åçš„æ•°æ®å‘é€ç»™ GeminiService
    4. è¿”å›ç»“æœï¼šåŒ…å«åŸå§‹æ•°æ®æ‘˜è¦å’Œ AI å»ºè®®
    
    Args:
        target_date: ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼ "YYYY-MM-DD"ã€‚å¦‚æœä¸æä¾›ï¼Œä½¿ç”¨ä»Šå¤©ã€‚
        garmin_client: GarminClient å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        garmin_service: GarminService å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        processor: DataProcessor å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
        gemini: GeminiService å®ä¾‹ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
    
    Returns:
        DailyAnalysisResponse: åŒ…å«æ—¥æœŸã€åŸå§‹æ•°æ®æ‘˜è¦å’Œ AI å»ºè®®
    """
    # è®°å½•è¯·æ±‚å¼€å§‹
    request_start_time = time.time()
    logger.info(f"[API] æ”¶åˆ°åˆ†æè¯·æ±‚: date={target_date or 'default'}")
    
    # ç¡®å®šç›®æ ‡æ—¥æœŸï¼ˆMock Mode é»˜è®¤ä½¿ç”¨ 2026-01-01ï¼‰
    if target_date:
        try:
            # éªŒè¯æ—¥æœŸæ ¼å¼
            datetime.strptime(target_date, "%Y-%m-%d")
            analysis_date = target_date
        except ValueError:
            raise HTTPException(
                status_code=400,
                detail=f"æ— æ•ˆçš„æ—¥æœŸæ ¼å¼: {target_date}ã€‚è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ã€‚"
            )
    else:
        # Mock Mode é»˜è®¤ä½¿ç”¨ 2026-01-01ï¼ˆæœ‰å®Œæ•´çš„ 20km è·‘æ­¥æ•°æ®ï¼‰
        analysis_date = "2026-01-01" if USE_MOCK_MODE else date.today().isoformat()

    analysis_date_obj = datetime.strptime(analysis_date, "%Y-%m-%d").date()

    # ========== DB Cache ==========
    db_user_id: Optional[int] = None
    cache_hours = max(int(settings.ANALYSIS_CACHE_HOURS), 0)
    if db is not None:
        try:
            user = get_or_create_user(db, garmin_email=settings.GARMIN_EMAIL)
            db_user_id = user.id
            if not force_refresh:
                cached = get_cached_analysis(db, user_id=db_user_id, analysis_date=analysis_date_obj)
                if cached is not None:
                    is_fresh = (
                        cache_hours > 0
                        and cached.generated_at is not None
                        and (datetime.utcnow() - cached.generated_at) <= timedelta(hours=cache_hours)
                    )
                    if is_fresh:
                        logger.info(f"[DB] Fresh analysis cache hit for {analysis_date}")
                        return DailyAnalysisResponse(
                            date=analysis_date,
                            raw_data_summary=cached.raw_data_summary_md,
                            ai_advice=cached.ai_advice_md,
                            charts=cached.charts_json,
                        )
                    logger.info(f"[DB] Analysis cache stale for {analysis_date}, rebuilding")
        except Exception as e:
            logger.warning(f"[DB] Cache lookup failed, continuing without cache: {e}")
            db_user_id = None
    
    try:
        # ========== æ­¥éª¤ 1: è·å–æ•°æ® ==========
        data_start_time = time.time()
        raw_health: Optional[Dict[str, Any]] = None
        raw_plan: List[Dict[str, Any]] = []
        raw_activities_new: List[Dict[str, Any]] = []
        data_source = "none"

        # ä¼˜å…ˆä» DB åŸå§‹æ•°æ®é‡å»ºï¼Œå‡å°‘ Garmin è¯·æ±‚é¢‘ç‡
        if not force_refresh and db is not None and db_user_id is not None:
            try:
                summary_row = get_daily_summary_by_date(db, user_id=db_user_id, summary_date=analysis_date_obj)
                activity_rows = get_activities_by_date(db, user_id=db_user_id, activity_date=analysis_date_obj)
                plan_rows = get_training_plans_in_range(
                    db,
                    user_id=db_user_id,
                    start_date=analysis_date_obj,
                    end_date=analysis_date_obj + timedelta(days=2),
                )

                if summary_row is not None:
                    raw_health = summary_row.raw_json or {
                        "date": analysis_date,
                        "sleep_time_hours": summary_row.sleep_time_hours,
                        "sleep_score": summary_row.sleep_score,
                        "body_battery": summary_row.body_battery,
                        "body_battery_charged": summary_row.body_battery_charged,
                        "body_battery_drained": summary_row.body_battery_drained,
                        "resting_heart_rate": summary_row.resting_heart_rate,
                        "average_stress_level": summary_row.average_stress_level,
                        "stress_qualifier": summary_row.stress_qualifier,
                        "hrv_status": summary_row.hrv_status,
                        "deep_sleep_seconds": summary_row.deep_sleep_seconds,
                        "rem_sleep_seconds": summary_row.rem_sleep_seconds,
                        "light_sleep_seconds": summary_row.light_sleep_seconds,
                        "awake_sleep_seconds": summary_row.awake_sleep_seconds,
                        "recovery_quality_percent": summary_row.recovery_quality_percent,
                    }

                for activity_row in activity_rows:
                    raw_activities_new.append(activity_row.raw_json or _activity_to_new_format_from_db(activity_row))

                for plan_row in plan_rows:
                    raw_plan.append(
                        plan_row.raw_json
                        or {
                            "date": plan_row.plan_date.isoformat(),
                            "workoutName": plan_row.workout_name,
                            "description": plan_row.description,
                        }
                    )

                if raw_health or raw_activities_new or raw_plan:
                    data_source = "db"
                    logger.info(f"[DB] Using stored raw data for {analysis_date}")
            except Exception as e:
                logger.warning(f"[DB] Failed to load raw data, fallback to Garmin: {e}")

        if data_source != "db":
            if USE_MOCK_MODE:
                # ========== Mock Mode: ä»æœ¬åœ° JSON æ–‡ä»¶è¯»å–æ•°æ® ==========
                try:
                    from backend.app.services.garmin_client import GarminClient as GC

                    mock_client = GC.__new__(GC)
                    mock_client.email = settings.GARMIN_EMAIL
                    mock_client.password = settings.GARMIN_PASSWORD
                    mock_client.is_cn = settings.GARMIN_IS_CN
                    mock_client.client = None

                    mock_activity, mock_health, mock_plan = mock_client.get_mock_data(analysis_date)
                    raw_health = mock_health
                    raw_plan = mock_plan or []
                    if mock_activity:
                        raw_activities_new = [mock_activity]
                    data_source = "mock"
                except Exception as e:
                    logger.error(f"[API] Mock æ•°æ®è¯»å–å¤±è´¥: {str(e)}")
                    raise HTTPException(
                        status_code=500,
                        detail=f"Mock æ•°æ®è¯»å–å¤±è´¥: {str(e)}"
                    )
            else:
                # ========== çœŸå®æ¨¡å¼: ä» Garmin API è·å–æ•°æ® ==========
                garmin_client = get_garmin_client()
                garmin_service = get_garmin_service()

                try:
                    daily_data = garmin_service.get_daily_data(analysis_date)
                    activities = daily_data.get("activities") or []
                    if activities:
                        raw_activities_new = [a for a in activities if isinstance(a, dict)]
                except Exception:
                    raw_activities_new = []

                try:
                    health_data = garmin_client.get_health_stats(analysis_date)
                    if health_data:
                        raw_health = health_data
                except Exception:
                    raw_health = None

                try:
                    plan_data = garmin_client.get_training_plan(analysis_date, days=3)
                    if plan_data:
                        raw_plan = plan_data
                except Exception:
                    raw_plan = []

                data_source = "garmin"

        activity_md, health_md, plan_md, converted_activities = _build_context_from_raw(
            processor=processor,
            raw_activities_new=raw_activities_new,
            raw_health=raw_health,
            raw_plan=raw_plan,
        )

        data_elapsed = time.time() - data_start_time
        logger.info(f"[API] æ•°æ®è·å–å®Œæˆï¼Œæ¥æº={data_source}ï¼Œè€—æ—¶ {data_elapsed:.2f}s")

        # ========== DB: Persist normalized raw data ==========
        if db is not None and db_user_id is not None and data_source in ("garmin", "mock"):
            try:
                if raw_health:
                    upsert_daily_summary(db, user_id=db_user_id, health=raw_health, summary_date=analysis_date_obj)
                if raw_activities_new:
                    upsert_activities(db, user_id=db_user_id, activities=raw_activities_new, fallback_date=analysis_date_obj)
                if raw_plan:
                    upsert_training_plans(db, user_id=db_user_id, plans=raw_plan)
                db.commit()
            except Exception as e:
                db.rollback()
                logger.warning(f"[DB] Failed to persist raw data: {e}")
        
        # ========== æ­¥éª¤ 2: æ¸…æ´—æ•°æ® ==========
        cleaning_start_time = time.time()
        # ä½¿ç”¨ DataProcessor å°†æ‰€æœ‰æ•°æ®ç»„åˆæˆå®Œæ•´çš„æ—¥æŠ¥ä¸Šä¸‹æ–‡
        daily_context = processor.assemble_daily_report(
            activity_md,
            health_md,
            plan_md,
            activity_date=analysis_date,
        )
        
        cleaning_elapsed = time.time() - cleaning_start_time
        logger.info(f"[API] æ•°æ®æ¸…æ´—å®Œæˆï¼Œè€—æ—¶ {cleaning_elapsed:.2f}s")
        
        # å¦‚æœæ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®
        if not daily_context or daily_context.strip() == "æš‚æ— æ•°æ®":
            logger.warning(f"[API] æœªè·å–åˆ°æ•°æ®ï¼Œè¿”å›ç©ºç»“æœ")

            empty_ai_advice = "## ğŸ“Š åˆ†æç»“æœ\n\n**æç¤º**: ä»Šå¤©è¿˜æ²¡æœ‰è¿åŠ¨æ•°æ®æˆ–å¥åº·æ•°æ®ã€‚è¯·ç¡®ä¿ Garmin è®¾å¤‡å·²åŒæ­¥æ•°æ®ã€‚"
            if db is not None and db_user_id is not None:
                try:
                    save_analysis(
                        db,
                        user_id=db_user_id,
                        analysis_date=analysis_date_obj,
                        raw_data_summary_md="æš‚æ— æ•°æ®",
                        ai_advice_md=empty_ai_advice,
                        charts_json=None,
                        model_name=getattr(gemini, "model_name", None),
                        status="no_data",
                        error_message=None,
                    )
                    db.commit()
                except Exception as e:
                    db.rollback()
                    logger.warning(f"[DB] Failed to persist empty analysis: {e}")

            return DailyAnalysisResponse(
                date=analysis_date,
                raw_data_summary="æš‚æ— æ•°æ®",
                ai_advice=empty_ai_advice,
                charts=None,
            )
        
        # ========== æ­¥éª¤ 3: AI åˆ†æ ==========
        ai_start_time = time.time()
        analysis_status = "success"
        analysis_error: Optional[str] = None
        try:
            ai_advice = gemini.analyze_training(daily_context)
            ai_elapsed = time.time() - ai_start_time
            logger.info(f"[API] AI åˆ†æå®Œæˆï¼Œè€—æ—¶ {ai_elapsed:.2f}s")
        except Exception as e:
            # AI åˆ†æå¤±è´¥ï¼Œè¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            logger.error(f"[API] AI åˆ†æå¤±è´¥: {str(e)}")
            analysis_status = "error"
            analysis_error = str(e)
            ai_advice = f"""## ğŸ“Š åˆ†æç»“æœ

**æŠ±æ­‰ï¼ŒAI åˆ†ææš‚æ—¶ä¸å¯ç”¨**

é”™è¯¯ä¿¡æ¯: {str(e)}

**å»ºè®®**: è¯·ç¨åé‡è¯•ï¼Œæˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚
"""
        
        # ========== æ­¥éª¤ 4: æå–å›¾è¡¨æ•°æ® ==========
        charts_data: Optional[Dict[str, List]] = None
        if converted_activities and len(converted_activities) > 0:
            # å–ç¬¬ä¸€ä¸ªæ´»åŠ¨æå–å›¾è¡¨æ•°æ®
            first_activity = converted_activities[0]
            try:
                charts_data = processor.extract_chart_data(first_activity)
            except Exception as e:
                logger.warning(f"[API] æå–å›¾è¡¨æ•°æ®å¤±è´¥: {str(e)}")
                charts_data = None

        # ========== DB: Persist analysis result ==========
        if db is not None and db_user_id is not None:
            try:
                save_analysis(
                    db,
                    user_id=db_user_id,
                    analysis_date=analysis_date_obj,
                    raw_data_summary_md=daily_context,
                    ai_advice_md=ai_advice,
                    charts_json=charts_data,
                    model_name=getattr(gemini, "model_name", None),
                    status=analysis_status,
                    error_message=analysis_error,
                )
                db.commit()
            except Exception as e:
                db.rollback()
                logger.warning(f"[DB] Failed to persist analysis: {e}")
        
        # ========== æ­¥éª¤ 5: è¿”å›ç»“æœ ==========
        total_elapsed = time.time() - request_start_time
        logger.info(f"[API] è¯·æ±‚å¤„ç†å®Œæ¯•ï¼Œå‡†å¤‡è¿”å›ï¼Œæ€»è€—æ—¶ {total_elapsed:.2f}s")
        logger.info(f"[API] æˆåŠŸæ‰“åŒ…å›¾è¡¨æ•°æ®å’ŒAIå»ºè®®")
        return DailyAnalysisResponse(
            date=analysis_date,
            raw_data_summary=daily_context,
            ai_advice=ai_advice,
            charts=charts_data,
        )
    
    except HTTPException:
        # é‡æ–°æŠ›å‡º HTTP å¼‚å¸¸
        raise
    except Exception as e:
        # æ•è·å…¶ä»–æœªé¢„æœŸçš„é”™è¯¯
        raise HTTPException(
            status_code=500,
            detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        "backend.app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
    )
